{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Labelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labelling for News Headline only as using News Headline to perform Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate by comparing labeled data from git (Compare with Vader, Afinn, Textblob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>classification</th>\n",
       "      <th>date</th>\n",
       "      <th>publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Attacks leave a Jewish community on edge as le...</td>\n",
       "      <td>https://www.theguardian.com/us-news/2019/dec/2...</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-12-29 19:00:45</td>\n",
       "      <td>The Guardian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US military carries out 'defensive strikes' in...</td>\n",
       "      <td>https://www.theguardian.com/us-news/2019/dec/2...</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-12-29 21:16:24</td>\n",
       "      <td>The Guardian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rebecca Long-Bailey makes opening pitch for La...</td>\n",
       "      <td>https://www.theguardian.com/politics/2019/dec/...</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-12-29 22:30:49</td>\n",
       "      <td>The Guardian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vaughan Oliver, celebrated 4AD graphic designe...</td>\n",
       "      <td>https://www.theguardian.com/music/2019/dec/29/...</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-12-29 21:31:55</td>\n",
       "      <td>The Guardian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'Remarkable' high as Scottish temperature reco...</td>\n",
       "      <td>https://www.theguardian.com/uk-news/2019/dec/2...</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-12-29 22:37:24</td>\n",
       "      <td>The Guardian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Attacks leave a Jewish community on edge as le...   \n",
       "1  US military carries out 'defensive strikes' in...   \n",
       "2  Rebecca Long-Bailey makes opening pitch for La...   \n",
       "3  Vaughan Oliver, celebrated 4AD graphic designe...   \n",
       "4  'Remarkable' high as Scottish temperature reco...   \n",
       "\n",
       "                                                 url  classification  \\\n",
       "0  https://www.theguardian.com/us-news/2019/dec/2...               1   \n",
       "1  https://www.theguardian.com/us-news/2019/dec/2...               0   \n",
       "2  https://www.theguardian.com/politics/2019/dec/...               1   \n",
       "3  https://www.theguardian.com/music/2019/dec/29/...               0   \n",
       "4  https://www.theguardian.com/uk-news/2019/dec/2...               1   \n",
       "\n",
       "                  date     publisher  \n",
       "0  2019-12-29 19:00:45  The Guardian  \n",
       "1  2019-12-29 21:16:24  The Guardian  \n",
       "2  2019-12-29 22:30:49  The Guardian  \n",
       "3  2019-12-29 21:31:55  The Guardian  \n",
       "4  2019-12-29 22:37:24  The Guardian  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load the dataset\n",
    "df = pd.read_csv('positivum-dataset.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publisher\n",
      "The Guardian    9180\n",
      "BBC             9164\n",
      "CNN             8973\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['publisher'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean labelled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the data that is CNN only\n",
    "df = df[df['publisher'] == 'CNN']\n",
    "df['classification'] = df['classification'].map({1: 'positive', 0: 'negative'})\n",
    "df = df[['title', 'classification']]\n",
    "df = df.rename(columns={'title': 'headline', 'classification': 'original_sentiment'})\n",
    "df = df.dropna()\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8819, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# classify sentiment\n",
    "def classify_sentiment(text):\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    compound = scores['compound']\n",
    "    if compound >= 0.05:\n",
    "        return 'positive'\n",
    "    elif compound <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# calculate sentiment score\n",
    "def calculate_sentiment_score(text):\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    return scores['compound']\n",
    "\n",
    "# apply the functions\n",
    "vader_df = df.copy()\n",
    "\n",
    "vader_df['vader_sentiment'] = vader_df['headline'].apply(classify_sentiment)\n",
    "vader_df['sentiment_score'] = vader_df['headline'].apply(calculate_sentiment_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from afinn import Afinn\n",
    "\n",
    "# afinn sentiment analyzer\n",
    "afinn = Afinn()\n",
    "\n",
    "def classify_sentiment(text):\n",
    "    score = afinn.score(text)\n",
    "    if score > 0:\n",
    "        return 'positive'\n",
    "    elif score < 0:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "def calculate_sentiment_score(text):\n",
    "    return afinn.score(text)\n",
    "\n",
    "afinn_df = df.copy()\n",
    "    \n",
    "afinn_df['afinn_sentiment'] = afinn_df['headline'].apply(classify_sentiment)\n",
    "afinn_df['sentiment_score'] = afinn_df['headline'].apply(calculate_sentiment_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def classify_sentiment(text):\n",
    "    analysis = TextBlob(text)\n",
    "    polarity = analysis.sentiment.polarity\n",
    "    \n",
    "    if polarity > 0:\n",
    "        return 'positive'\n",
    "    elif polarity < 0:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "    \n",
    "def calculate_sentiment_score(text):\n",
    "    analysis = TextBlob(text)\n",
    "    return analysis.sentiment.polarity\n",
    "\n",
    "textblob_df = df.copy()\n",
    "\n",
    "    \n",
    "textblob_df['textblob_sentiment'] = textblob_df['headline'].apply(classify_sentiment)\n",
    "textblob_df['sentiment_score'] = textblob_df['headline'].apply(calculate_sentiment_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create New Column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete for vader_df. DataFrame has been updated.\n",
      "Processing complete for afinn_df. DataFrame has been updated.\n",
      "Processing complete for textblob_df. DataFrame has been updated.\n"
     ]
    }
   ],
   "source": [
    "# define DataFrames and their column names for each sentiment analysis method\n",
    "dataframes = {\n",
    "    'vader_df': {'df': vader_df, 'sentiment_column': 'vader_sentiment', 'label_column': 'original_sentiment'},\n",
    "    'afinn_df': {'df': afinn_df, 'sentiment_column': 'afinn_sentiment', 'label_column': 'original_sentiment'},\n",
    "    'textblob_df': {'df': textblob_df, 'sentiment_column': 'textblob_sentiment', 'label_column': 'original_sentiment'}\n",
    "}\n",
    "\n",
    "# iterate over each DataFrame\n",
    "for df_name, info in dataframes.items():\n",
    "    df = info['df']\n",
    "    sentiment_col = info['sentiment_column']\n",
    "    label_col = info['label_column']\n",
    "    \n",
    "    # check and ensure columns exist\n",
    "    if sentiment_col in df.columns and label_col in df.columns:\n",
    "        # create a new column based on sentiment comparison\n",
    "        df['new_column'] = df.apply(\n",
    "            lambda row: 1 if ((row[sentiment_col] in ['positive', 'neutral'] and row[label_col] in ['positive', 'neutral']) or \n",
    "                              (row[sentiment_col] == 'negative' and row[label_col] == 'negative')) \n",
    "                        else 0, \n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        print(f\"Processing complete for {df_name}. DataFrame has been updated.\")\n",
    "    else:\n",
    "        print(f\"Columns {sentiment_col} or {label_col} not found in {df_name}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count same occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for vader_df:\n",
      "new_column\n",
      "1    5762\n",
      "0    3057\n",
      "Name: count, dtype: int64\n",
      "Total occurrences: 8819\n",
      "\n",
      "Results for afinn_df:\n",
      "new_column\n",
      "1    5896\n",
      "0    2923\n",
      "Name: count, dtype: int64\n",
      "Total occurrences: 8819\n",
      "\n",
      "Results for textblob_df:\n",
      "new_column\n",
      "1    4913\n",
      "0    3906\n",
      "Name: count, dtype: int64\n",
      "Total occurrences: 8819\n"
     ]
    }
   ],
   "source": [
    "dataframes = {\n",
    "    'vader_df': {'df': vader_df, 'new_column': 'new_column'},\n",
    "    'afinn_df': {'df': afinn_df, 'new_column': 'new_column'},\n",
    "    'textblob_df': {'df': textblob_df, 'new_column': 'new_column'}\n",
    "}\n",
    "\n",
    "for df_name, info in dataframes.items():\n",
    "    df = info['df']\n",
    "    new_col = info['new_column']\n",
    "    \n",
    "    # check and ensure the new_column exists\n",
    "    if new_col in df.columns:\n",
    "        # count occurrences of each unique value in the new_column\n",
    "        category_counts = df[new_col].value_counts()\n",
    "        \n",
    "        # get the total number of occurrences\n",
    "        total_occurrences = category_counts.sum()\n",
    "        \n",
    "        print(f\"\\nResults for {df_name}:\")\n",
    "        print(category_counts)\n",
    "        print(\"Total occurrences:\", total_occurrences)\n",
    "    else:\n",
    "        print(f\"Column {new_col} not found in {df_name}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation \n",
    "\n",
    "#### Vader \n",
    "\n",
    "1 = 5762\n",
    "\n",
    "0 = 3057\n",
    "\n",
    "5762/8819 = 0.6534\n",
    "\n",
    "= 65%\n",
    "\n",
    "#### Afinn\n",
    "\n",
    "1 = 5896\n",
    "\n",
    "0 = 2923\n",
    "\n",
    "5896/8819 = 0.6686\n",
    "\n",
    "= 67%\n",
    "\n",
    "#### Textblob\n",
    "\n",
    "1 = 4913\n",
    "\n",
    "0 = 3906\n",
    "\n",
    "4913/8819 = 0.5571\n",
    "\n",
    "= 56%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply Afinn to original dataset (cnn_news_articles_final_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "df = pd.read_csv('cnn_news_articles_final_cleaned.csv')\n",
    "\n",
    "from afinn import Afinn\n",
    "\n",
    "# afinn sentiment analyzer\n",
    "afinn = Afinn()\n",
    "\n",
    "def classify_sentiment(text):\n",
    "    score = afinn.score(text)\n",
    "    if score > 0:\n",
    "        return 'positive'\n",
    "    elif score < 0:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "def calculate_sentiment_score(text):\n",
    "    return afinn.score(text)\n",
    "    \n",
    "df['sentiment'] = df['headline'].apply(classify_sentiment)\n",
    "df['sentiment_score'] = df['headline'].apply(calculate_sentiment_score)\n",
    "\n",
    "df.to_csv('cnn_news_articles_final_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "neutral     16863\n",
       "negative    14666\n",
       "positive    10159\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
