{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the Columns that relevant to the scopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load the dataset\n",
    "df = pd.read_csv('cnn_news_articles_final.csv')\n",
    "\n",
    "# select the selected columns\n",
    "df = df[['Date published', 'Category', 'Headline', 'Article text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renamned columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "df = df.rename(columns={\n",
    "    'Date published': 'date published',\n",
    "    'Category': 'category',\n",
    "    'Headline': 'headline',\n",
    "    'Article text': 'text'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop N/A (Except Date Published)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Drop: \n",
      "date published    3928\n",
      "category             0\n",
      "headline             0\n",
      "text                 9\n",
      "dtype: int64\n",
      "\n",
      "After Drop: \n",
      "date published    3928\n",
      "category             0\n",
      "headline             0\n",
      "text                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# drop missing values\n",
    "print(\"Before Drop: \")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "df = df.dropna(subset=['text'])\n",
    "\n",
    "print(\"\\nAfter Drop: \")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop Duplicated (Just Incase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Duplicated: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date published</th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [date published, category, headline, text]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check duplicated\n",
    "print('Total Duplicated:', df.duplicated().sum())\n",
    "\n",
    "# review duplicated\n",
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Outliers in Category column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Drop: \n",
      "category\n",
      "news             18069\n",
      "sport            15788\n",
      "politics          3026\n",
      "business          1775\n",
      "health            1037\n",
      "world              820\n",
      "entertainment      557\n",
      "us                 317\n",
      "opinions           280\n",
      "weather            115\n",
      "travel              52\n",
      "style               16\n",
      "cnn                 11\n",
      "vr                   5\n",
      "Name: count, dtype: int64\n",
      "\n",
      "After Drop: \n",
      "category\n",
      "news             18069\n",
      "sport            15788\n",
      "politics          3026\n",
      "business          1775\n",
      "health            1037\n",
      "world              820\n",
      "entertainment      557\n",
      "us                 317\n",
      "opinions           280\n",
      "weather            115\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# value counts Category\n",
    "category_counts = df['category'].value_counts()\n",
    "print(\"Before Drop: \")\n",
    "print(category_counts)\n",
    "\n",
    "# list of categories to remove\n",
    "categories_to_remove = ['travel', 'style', 'cnn', 'vr']\n",
    "\n",
    "# remove rows with specified categories\n",
    "df = df[~df['category'].isin(categories_to_remove)]\n",
    "\n",
    "# value counts Category column after removed\n",
    "category_counts_after_removal = df['category'].value_counts()\n",
    "print(\"\\nAfter Drop: \")\n",
    "print(category_counts_after_removal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing the 3928 missing date data (Metadata given is 2023-01-01 to 2023-10-06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# sequential dates from 2023-01-01 to 2023-10-06\n",
    "start_date = datetime.strptime('2023-01-01', '%Y-%m-%d')\n",
    "end_date = datetime.strptime('2023-10-06', '%Y-%m-%d')\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "\n",
    "# convert to datetime format\n",
    "df['date published'] = pd.to_datetime(df['date published'], errors='coerce')\n",
    "\n",
    "# find where dates are missing\n",
    "missing_indices = df[df['date published'].isna()].index\n",
    "\n",
    "# count number of missing dates\n",
    "num_missing = len(missing_indices)\n",
    "\n",
    "# count number of dates in the range\n",
    "num_dates = len(date_range)\n",
    "\n",
    "# count how many times each date should be repeated\n",
    "repeats_per_date = num_missing // num_dates\n",
    "extra_repeats = num_missing % num_dates\n",
    "\n",
    "# create list to fill the missing dates\n",
    "fill_dates = []\n",
    "for date in date_range:\n",
    "    fill_dates.extend([date] * repeats_per_date)\n",
    "\n",
    "# assign the extra repeats to the first few dates\n",
    "for i in range(extra_repeats):\n",
    "    fill_dates.append(date_range[i])\n",
    "\n",
    "# sort the dates from 2023-01-01 to 2023-10-06\n",
    "fill_dates = sorted(fill_dates)\n",
    "\n",
    "# start filling\n",
    "for i, index in enumerate(missing_indices):\n",
    "    df.at[index, 'date published'] = fill_dates[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last check after cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date published    0\n",
      "category          0\n",
      "headline          0\n",
      "text              0\n",
      "dtype: int64\n",
      "0\n",
      "(41784, 4)\n"
     ]
    }
   ],
   "source": [
    "# last check missing values \n",
    "print(df.isnull().sum())\n",
    "\n",
    "# last check duplicated\n",
    "print(df.duplicated().sum())\n",
    "\n",
    "# dimensions \n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joe Chok\\AppData\\Local\\Temp\\ipykernel_17508\\2321103012.py:9: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[['text', 'headline']] = df[['text', 'headline']].applymap(lowercase_text)\n",
      "C:\\Users\\Joe Chok\\AppData\\Local\\Temp\\ipykernel_17508\\2321103012.py:10: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[['text', 'headline']] = df[['text', 'headline']].applymap(replace_apostrophe)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date published</th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-15 02:46:59</td>\n",
       "      <td>news</td>\n",
       "      <td>there's a shortage of truckers, but tusimple t...</td>\n",
       "      <td>(cnn)right now, there's a shortage of truck d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-12 07:52:09</td>\n",
       "      <td>news</td>\n",
       "      <td>bioservo's robotic 'ironhand' could protect fa...</td>\n",
       "      <td>(cnn)working in a factory or warehouse can me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-16 02:51:30</td>\n",
       "      <td>news</td>\n",
       "      <td>this swarm of robots gets smarter the more it ...</td>\n",
       "      <td>(cnn)in a hong kong warehouse, a swarm of aut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-03-18 14:37:21</td>\n",
       "      <td>business</td>\n",
       "      <td>two years later, remote work has changed milli...</td>\n",
       "      <td>the pandemic thrust the working world into a n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-03-19 11:41:08</td>\n",
       "      <td>business</td>\n",
       "      <td>why march is so volatile for stocks - cnn</td>\n",
       "      <td>new york (cnn business)march madness isn't jus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-03-20 11:36:43</td>\n",
       "      <td>business</td>\n",
       "      <td>stocks week ahead: big oil rakes in billions a...</td>\n",
       "      <td>a version of this story first appeared in cnn ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-03-18 14:26:26</td>\n",
       "      <td>business</td>\n",
       "      <td>oil 'emergency': work from home and drive slow...</td>\n",
       "      <td>new york (cnn business)governments around the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-03-20 12:57:36</td>\n",
       "      <td>business</td>\n",
       "      <td>opinion: technology is transforming the nature...</td>\n",
       "      <td>this interview has been edited from its origin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-03-18 17:14:11</td>\n",
       "      <td>business</td>\n",
       "      <td>inflation is everywhere. except your cell phon...</td>\n",
       "      <td>new york (cnn business)inflation is everywhere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-03-18 11:32:30</td>\n",
       "      <td>business</td>\n",
       "      <td>burger king partner 'refuses' to close 800 rus...</td>\n",
       "      <td>new york (cnn business)burger king is trying t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date published  category  \\\n",
       "0 2021-07-15 02:46:59      news   \n",
       "1 2021-05-12 07:52:09      news   \n",
       "2 2021-06-16 02:51:30      news   \n",
       "3 2022-03-18 14:37:21  business   \n",
       "4 2022-03-19 11:41:08  business   \n",
       "5 2022-03-20 11:36:43  business   \n",
       "6 2022-03-18 14:26:26  business   \n",
       "7 2022-03-20 12:57:36  business   \n",
       "8 2022-03-18 17:14:11  business   \n",
       "9 2022-03-18 11:32:30  business   \n",
       "\n",
       "                                            headline  \\\n",
       "0  there's a shortage of truckers, but tusimple t...   \n",
       "1  bioservo's robotic 'ironhand' could protect fa...   \n",
       "2  this swarm of robots gets smarter the more it ...   \n",
       "3  two years later, remote work has changed milli...   \n",
       "4          why march is so volatile for stocks - cnn   \n",
       "5  stocks week ahead: big oil rakes in billions a...   \n",
       "6  oil 'emergency': work from home and drive slow...   \n",
       "7  opinion: technology is transforming the nature...   \n",
       "8  inflation is everywhere. except your cell phon...   \n",
       "9  burger king partner 'refuses' to close 800 rus...   \n",
       "\n",
       "                                                text  \n",
       "0   (cnn)right now, there's a shortage of truck d...  \n",
       "1   (cnn)working in a factory or warehouse can me...  \n",
       "2   (cnn)in a hong kong warehouse, a swarm of aut...  \n",
       "3  the pandemic thrust the working world into a n...  \n",
       "4  new york (cnn business)march madness isn't jus...  \n",
       "5  a version of this story first appeared in cnn ...  \n",
       "6  new york (cnn business)governments around the ...  \n",
       "7  this interview has been edited from its origin...  \n",
       "8  new york (cnn business)inflation is everywhere...  \n",
       "9  new york (cnn business)burger king is trying t...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lowercase text \n",
    "def lowercase_text(text):\n",
    "    return text.lower()\n",
    "\n",
    "# change apostrophe \n",
    "def replace_apostrophe(text):\n",
    "    return text.replace(\"â€™\", \"'\")\n",
    "\n",
    "df[['text', 'headline']] = df[['text', 'headline']].applymap(lowercase_text)\n",
    "df[['text', 'headline']] = df[['text', 'headline']].applymap(replace_apostrophe)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date published</th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-15 02:46:59</td>\n",
       "      <td>news</td>\n",
       "      <td>there's a shortage of truckers but tu simple t...</td>\n",
       "      <td>cnn right now there's a shortage of truck driv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-12 07:52:09</td>\n",
       "      <td>news</td>\n",
       "      <td>bio servo's robotic ' iron hand ' could protec...</td>\n",
       "      <td>cnn working in a factory or warehouse can mean...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-16 02:51:30</td>\n",
       "      <td>news</td>\n",
       "      <td>this swarm of robots gets smarter the more it ...</td>\n",
       "      <td>cnn in a hong kong warehouse a swarm of autono...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-03-18 14:37:21</td>\n",
       "      <td>business</td>\n",
       "      <td>two years later remote work has changed millio...</td>\n",
       "      <td>the pandemic thrust the working world into a n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-03-19 11:41:08</td>\n",
       "      <td>business</td>\n",
       "      <td>why march is so volatile for stocks cnn</td>\n",
       "      <td>new york cnn business march madness isn't just...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-03-20 11:36:43</td>\n",
       "      <td>business</td>\n",
       "      <td>stocks week ahead big oil rakes in billions as...</td>\n",
       "      <td>a version of this story first appeared in cnn ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-03-18 14:26:26</td>\n",
       "      <td>business</td>\n",
       "      <td>oil ' emergency ' work from home and drive slo...</td>\n",
       "      <td>new york cnn business governments around the w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-03-20 12:57:36</td>\n",
       "      <td>business</td>\n",
       "      <td>opinion technology is transforming the nature ...</td>\n",
       "      <td>this interview has been edited from its origin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-03-18 17:14:11</td>\n",
       "      <td>business</td>\n",
       "      <td>inflation is everywhere except your cell phone...</td>\n",
       "      <td>new york cnn business inflation is everywhere ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-03-18 11:32:30</td>\n",
       "      <td>business</td>\n",
       "      <td>burger king partner ' refuses ' to close 800 r...</td>\n",
       "      <td>new york cnn business burger king is trying to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date published  category  \\\n",
       "0 2021-07-15 02:46:59      news   \n",
       "1 2021-05-12 07:52:09      news   \n",
       "2 2021-06-16 02:51:30      news   \n",
       "3 2022-03-18 14:37:21  business   \n",
       "4 2022-03-19 11:41:08  business   \n",
       "5 2022-03-20 11:36:43  business   \n",
       "6 2022-03-18 14:26:26  business   \n",
       "7 2022-03-20 12:57:36  business   \n",
       "8 2022-03-18 17:14:11  business   \n",
       "9 2022-03-18 11:32:30  business   \n",
       "\n",
       "                                            headline  \\\n",
       "0  there's a shortage of truckers but tu simple t...   \n",
       "1  bio servo's robotic ' iron hand ' could protec...   \n",
       "2  this swarm of robots gets smarter the more it ...   \n",
       "3  two years later remote work has changed millio...   \n",
       "4            why march is so volatile for stocks cnn   \n",
       "5  stocks week ahead big oil rakes in billions as...   \n",
       "6  oil ' emergency ' work from home and drive slo...   \n",
       "7  opinion technology is transforming the nature ...   \n",
       "8  inflation is everywhere except your cell phone...   \n",
       "9  burger king partner ' refuses ' to close 800 r...   \n",
       "\n",
       "                                                text  \n",
       "0  cnn right now there's a shortage of truck driv...  \n",
       "1  cnn working in a factory or warehouse can mean...  \n",
       "2  cnn in a hong kong warehouse a swarm of autono...  \n",
       "3  the pandemic thrust the working world into a n...  \n",
       "4  new york cnn business march madness isn't just...  \n",
       "5  a version of this story first appeared in cnn ...  \n",
       "6  new york cnn business governments around the w...  \n",
       "7  this interview has been edited from its origin...  \n",
       "8  new york cnn business inflation is everywhere ...  \n",
       "9  new york cnn business burger king is trying to...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wordninja\n",
    "\n",
    "# Word Segmentation on text column\n",
    "df['headline'] = df['headline'].apply(lambda x: ' '.join(wordninja.split(x)))\n",
    "df['text'] = df['text'].apply(lambda x: ' '.join(wordninja.split(x)))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date published</th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-15 02:46:59</td>\n",
       "      <td>news</td>\n",
       "      <td>there is a shortage of truckers but tu simple ...</td>\n",
       "      <td>cnn right now there is a shortage of truck dri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-12 07:52:09</td>\n",
       "      <td>news</td>\n",
       "      <td>bio servo's robotic ' iron hand ' could protec...</td>\n",
       "      <td>cnn working in a factory or warehouse can mean...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-16 02:51:30</td>\n",
       "      <td>news</td>\n",
       "      <td>this swarm of robots gets smarter the more it ...</td>\n",
       "      <td>cnn in a hong kong warehouse a swarm of autono...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-03-18 14:37:21</td>\n",
       "      <td>business</td>\n",
       "      <td>two years later remote work has changed millio...</td>\n",
       "      <td>the pandemic thrust the working world into a n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-03-19 11:41:08</td>\n",
       "      <td>business</td>\n",
       "      <td>why march is so volatile for stocks cnn</td>\n",
       "      <td>new york cnn business march madness is not jus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-03-20 11:36:43</td>\n",
       "      <td>business</td>\n",
       "      <td>stocks week ahead big oil rakes in billions as...</td>\n",
       "      <td>a version of this story first appeared in cnn ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-03-18 14:26:26</td>\n",
       "      <td>business</td>\n",
       "      <td>oil ' emergency ' work from home and drive slo...</td>\n",
       "      <td>new york cnn business governments around the w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-03-20 12:57:36</td>\n",
       "      <td>business</td>\n",
       "      <td>opinion technology is transforming the nature ...</td>\n",
       "      <td>this interview has been edited from its origin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-03-18 17:14:11</td>\n",
       "      <td>business</td>\n",
       "      <td>inflation is everywhere except your cell phone...</td>\n",
       "      <td>new york cnn business inflation is everywhere ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-03-18 11:32:30</td>\n",
       "      <td>business</td>\n",
       "      <td>burger king partner ' refuses ' to close 800 r...</td>\n",
       "      <td>new york cnn business burger king is trying to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date published  category  \\\n",
       "0 2021-07-15 02:46:59      news   \n",
       "1 2021-05-12 07:52:09      news   \n",
       "2 2021-06-16 02:51:30      news   \n",
       "3 2022-03-18 14:37:21  business   \n",
       "4 2022-03-19 11:41:08  business   \n",
       "5 2022-03-20 11:36:43  business   \n",
       "6 2022-03-18 14:26:26  business   \n",
       "7 2022-03-20 12:57:36  business   \n",
       "8 2022-03-18 17:14:11  business   \n",
       "9 2022-03-18 11:32:30  business   \n",
       "\n",
       "                                            headline  \\\n",
       "0  there is a shortage of truckers but tu simple ...   \n",
       "1  bio servo's robotic ' iron hand ' could protec...   \n",
       "2  this swarm of robots gets smarter the more it ...   \n",
       "3  two years later remote work has changed millio...   \n",
       "4            why march is so volatile for stocks cnn   \n",
       "5  stocks week ahead big oil rakes in billions as...   \n",
       "6  oil ' emergency ' work from home and drive slo...   \n",
       "7  opinion technology is transforming the nature ...   \n",
       "8  inflation is everywhere except your cell phone...   \n",
       "9  burger king partner ' refuses ' to close 800 r...   \n",
       "\n",
       "                                                text  \n",
       "0  cnn right now there is a shortage of truck dri...  \n",
       "1  cnn working in a factory or warehouse can mean...  \n",
       "2  cnn in a hong kong warehouse a swarm of autono...  \n",
       "3  the pandemic thrust the working world into a n...  \n",
       "4  new york cnn business march madness is not jus...  \n",
       "5  a version of this story first appeared in cnn ...  \n",
       "6  new york cnn business governments around the w...  \n",
       "7  this interview has been edited from its origin...  \n",
       "8  new york cnn business inflation is everywhere ...  \n",
       "9  new york cnn business burger king is trying to...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import contractions\n",
    "\n",
    "# expand the words like cnnt to cannot / ve to have and so on\n",
    "def expand_contractions(text):\n",
    "\n",
    "    expanded_text = contractions.fix(text)\n",
    "    return expanded_text\n",
    "\n",
    "df['headline'] = df['headline'].apply(expand_contractions)\n",
    "df['text'] = df['text'].apply(expand_contractions)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "import re\n",
    "from emoticons_lib import emoticons_lib\n",
    "\n",
    "# convert emoticon with text   { :), :( }\n",
    "def convert_emojis_with_text(text):\n",
    "    emoticon_pattern = re.compile('|'.join(re.escape(emoticon) for emoticon in emoticons_lib.keys()))\n",
    "    return emoticon_pattern.sub(lambda match: emoticons_lib[match.group(0)], text)\n",
    "\n",
    "# list of columns to apply the functions\n",
    "columns_to_transform = ['text', 'headline']\n",
    "\n",
    "# apply the functions to both columns\n",
    "for column in columns_to_transform:\n",
    "    df[column] = df[column].apply(lambda e: convert_emojis_with_text(e))\n",
    "\n",
    "    # convert emojis to text\n",
    "    df[column] = df[column].apply(lambda e: emoji.demojize(e, language=\"en\"))\n",
    "\n",
    "    # replace underscore with whitespace (caused by emojis text like ðŸ˜Š convert to :smiling_smiling_face ï¼‰\n",
    "    df[column] = df[column].apply(lambda e: e.replace('_', ' '))\n",
    "\n",
    "    # remove semicolon with whitespace (caused by emojis text)\n",
    "    df[column] = df[column].apply(lambda e: e.replace(':', ' '))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date published</th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-15 02:46:59</td>\n",
       "      <td>news</td>\n",
       "      <td>there is a shortage of truckers but tu simple ...</td>\n",
       "      <td>right now there is a shortage of truck driver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-12 07:52:09</td>\n",
       "      <td>news</td>\n",
       "      <td>bio servo's robotic ' iron hand ' could protec...</td>\n",
       "      <td>working in a factory or warehouse can mean do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-16 02:51:30</td>\n",
       "      <td>news</td>\n",
       "      <td>this swarm of robots gets smarter the more it ...</td>\n",
       "      <td>in a hong kong warehouse a swarm of autonomou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-03-18 14:37:21</td>\n",
       "      <td>business</td>\n",
       "      <td>two years later remote work has changed millio...</td>\n",
       "      <td>the pandemic thrust the working world into a n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-03-19 11:41:08</td>\n",
       "      <td>business</td>\n",
       "      <td>why march is so volatile for stocks</td>\n",
       "      <td>new york  business march madness is not just f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-03-20 11:36:43</td>\n",
       "      <td>business</td>\n",
       "      <td>stocks week ahead big oil rakes in billions as...</td>\n",
       "      <td>a version of this story first appeared in  bus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-03-18 14:26:26</td>\n",
       "      <td>business</td>\n",
       "      <td>oil ' emergency ' work from home and drive slo...</td>\n",
       "      <td>new york  business governments around the worl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-03-20 12:57:36</td>\n",
       "      <td>business</td>\n",
       "      <td>opinion technology is transforming the nature ...</td>\n",
       "      <td>this interview has been edited from its origin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-03-18 17:14:11</td>\n",
       "      <td>business</td>\n",
       "      <td>inflation is everywhere except your cell phone...</td>\n",
       "      <td>new york  business inflation is everywhere gro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-03-18 11:32:30</td>\n",
       "      <td>business</td>\n",
       "      <td>burger king partner ' refuses ' to close 800 r...</td>\n",
       "      <td>new york  business burger king is trying to su...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date published  category  \\\n",
       "0 2021-07-15 02:46:59      news   \n",
       "1 2021-05-12 07:52:09      news   \n",
       "2 2021-06-16 02:51:30      news   \n",
       "3 2022-03-18 14:37:21  business   \n",
       "4 2022-03-19 11:41:08  business   \n",
       "5 2022-03-20 11:36:43  business   \n",
       "6 2022-03-18 14:26:26  business   \n",
       "7 2022-03-20 12:57:36  business   \n",
       "8 2022-03-18 17:14:11  business   \n",
       "9 2022-03-18 11:32:30  business   \n",
       "\n",
       "                                            headline  \\\n",
       "0  there is a shortage of truckers but tu simple ...   \n",
       "1  bio servo's robotic ' iron hand ' could protec...   \n",
       "2  this swarm of robots gets smarter the more it ...   \n",
       "3  two years later remote work has changed millio...   \n",
       "4               why march is so volatile for stocks    \n",
       "5  stocks week ahead big oil rakes in billions as...   \n",
       "6  oil ' emergency ' work from home and drive slo...   \n",
       "7  opinion technology is transforming the nature ...   \n",
       "8  inflation is everywhere except your cell phone...   \n",
       "9  burger king partner ' refuses ' to close 800 r...   \n",
       "\n",
       "                                                text  \n",
       "0   right now there is a shortage of truck driver...  \n",
       "1   working in a factory or warehouse can mean do...  \n",
       "2   in a hong kong warehouse a swarm of autonomou...  \n",
       "3  the pandemic thrust the working world into a n...  \n",
       "4  new york  business march madness is not just f...  \n",
       "5  a version of this story first appeared in  bus...  \n",
       "6  new york  business governments around the worl...  \n",
       "7  this interview has been edited from its origin...  \n",
       "8  new york  business inflation is everywhere gro...  \n",
       "9  new york  business burger king is trying to su...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove 'cnn' word in text column\n",
    "def remove_cnn(text):\n",
    "    return text.replace('cnn', '')\n",
    "\n",
    "df['headline'] = df['headline'].apply(remove_cnn)\n",
    "df['text'] = df['text'].apply(remove_cnn)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:18: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:18: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\Joe Chok\\AppData\\Local\\Temp\\ipykernel_17508\\3308738698.py:18: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  return re.sub('[^a-zA-Z\\s]', ' ', text)\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Joe\n",
      "[nltk_data]     Chok\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Joe\n",
      "[nltk_data]     Chok\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date published</th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-15 02:46:59</td>\n",
       "      <td>news</td>\n",
       "      <td>shortage trucker simple think solution driver ...</td>\n",
       "      <td>right shortage truck driver worldwide exacerba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-12 07:52:09</td>\n",
       "      <td>news</td>\n",
       "      <td>bio servo robotic iron hand could protect fact...</td>\n",
       "      <td>working factory warehouse mean task repetition...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-16 02:51:30</td>\n",
       "      <td>news</td>\n",
       "      <td>swarm robot get smarter work</td>\n",
       "      <td>hong kong warehouse swarm autonomous robot wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-03-18 14:37:21</td>\n",
       "      <td>business</td>\n",
       "      <td>two year later remote work changed million career</td>\n",
       "      <td>pandemic thrust working world new reality marc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-03-19 11:41:08</td>\n",
       "      <td>business</td>\n",
       "      <td>march volatile stock</td>\n",
       "      <td>new york business march madness college basket...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-03-20 11:36:43</td>\n",
       "      <td>business</td>\n",
       "      <td>stock week ahead big oil rake billion price so...</td>\n",
       "      <td>version story first appeared business bell new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-03-18 14:26:26</td>\n",
       "      <td>business</td>\n",
       "      <td>oil emergency work home drive slower iea say</td>\n",
       "      <td>new york business government around world must...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-03-20 12:57:36</td>\n",
       "      <td>business</td>\n",
       "      <td>opinion technology transforming nature money a...</td>\n",
       "      <td>interview edited original version originally p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-03-18 17:14:11</td>\n",
       "      <td>business</td>\n",
       "      <td>inflation everywhere except cell phone bill</td>\n",
       "      <td>new york business inflation everywhere grocery...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-03-18 11:32:30</td>\n",
       "      <td>business</td>\n",
       "      <td>burger king partner refuse close russian location</td>\n",
       "      <td>new york business burger king trying suspend o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date published  category  \\\n",
       "0 2021-07-15 02:46:59      news   \n",
       "1 2021-05-12 07:52:09      news   \n",
       "2 2021-06-16 02:51:30      news   \n",
       "3 2022-03-18 14:37:21  business   \n",
       "4 2022-03-19 11:41:08  business   \n",
       "5 2022-03-20 11:36:43  business   \n",
       "6 2022-03-18 14:26:26  business   \n",
       "7 2022-03-20 12:57:36  business   \n",
       "8 2022-03-18 17:14:11  business   \n",
       "9 2022-03-18 11:32:30  business   \n",
       "\n",
       "                                            headline  \\\n",
       "0  shortage trucker simple think solution driver ...   \n",
       "1  bio servo robotic iron hand could protect fact...   \n",
       "2                       swarm robot get smarter work   \n",
       "3  two year later remote work changed million career   \n",
       "4                               march volatile stock   \n",
       "5  stock week ahead big oil rake billion price so...   \n",
       "6       oil emergency work home drive slower iea say   \n",
       "7  opinion technology transforming nature money a...   \n",
       "8        inflation everywhere except cell phone bill   \n",
       "9  burger king partner refuse close russian location   \n",
       "\n",
       "                                                text  \n",
       "0  right shortage truck driver worldwide exacerba...  \n",
       "1  working factory warehouse mean task repetition...  \n",
       "2  hong kong warehouse swarm autonomous robot wor...  \n",
       "3  pandemic thrust working world new reality marc...  \n",
       "4  new york business march madness college basket...  \n",
       "5  version story first appeared business bell new...  \n",
       "6  new york business government around world must...  \n",
       "7  interview edited original version originally p...  \n",
       "8  new york business inflation everywhere grocery...  \n",
       "9  new york business burger king trying suspend o...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# remove words =  or > 2 characters\n",
    "def remove_short_words(text):\n",
    "    return ' '.join([word for word in text.split() if len(word) > 2])\n",
    "\n",
    "# remove symbols\n",
    "def remove_symbols(text):\n",
    "    symbol_pattern = re.compile(r'[\\(\\)\\[\\]:]')\n",
    "    return symbol_pattern.sub('', text)\n",
    "\n",
    "# remove symbols and digits\n",
    "def remove_symbols_digits(text):\n",
    "    return re.sub('[^a-zA-Z\\s]', ' ', text)\n",
    "\n",
    "# remove URLs\n",
    "def remove_urls(text):\n",
    "    return re.sub(r'http\\S+', '', text)\n",
    "\n",
    "# remove HTML tags\n",
    "def remove_html_tags(text):\n",
    "    return re.sub(r'<[^>]+>', '', text)\n",
    "\n",
    "# remove extra whitespace\n",
    "def remove_whitespace(text):\n",
    "    return ' '.join(text.split())\n",
    "\n",
    "# remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    return re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "# remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    return ' '.join([token for token in text.split() if token.lower() not in stop_words])\n",
    "\n",
    "# lemmatizing text\n",
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return ' '.join([lemmatizer.lemmatize(token) for token in text.split()])\n",
    "\n",
    "# list of columns to apply the functions\n",
    "columns_to_transform = ['text', 'headline']\n",
    "\n",
    "# apply the functions to both columns\n",
    "for column in columns_to_transform:\n",
    "    df[column] = df[column].apply(remove_short_words)\n",
    "    df[column] = df[column].apply(remove_symbols)\n",
    "    df[column] = df[column].apply(remove_symbols_digits)\n",
    "    df[column] = df[column].apply(remove_urls)\n",
    "    df[column] = df[column].apply(remove_html_tags)\n",
    "    df[column] = df[column].apply(remove_whitespace)\n",
    "    df[column] = df[column].apply(remove_punctuation)\n",
    "    df[column] = df[column].apply(remove_stopwords)\n",
    "    df[column] = df[column].apply(lemmatize_text)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to C:\\Users\\Joe\n",
      "[nltk_data]     Chok\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Joe\n",
      "[nltk_data]     Chok\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date published</th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-15 02:46:59</td>\n",
       "      <td>news</td>\n",
       "      <td>shortage trucker simple think solution driver</td>\n",
       "      <td>right shortage truck driver commerce boom brou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-12 07:52:09</td>\n",
       "      <td>news</td>\n",
       "      <td>servo iron hand could protect factory worker i...</td>\n",
       "      <td>working factory warehouse mean task repetition...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-16 02:51:30</td>\n",
       "      <td>news</td>\n",
       "      <td>swarm robot get work</td>\n",
       "      <td>hong warehouse swarm autonomous robot work wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-03-18 14:37:21</td>\n",
       "      <td>business</td>\n",
       "      <td>two year later remote work million career</td>\n",
       "      <td>pandemic thrust working world new reality marc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-03-19 11:41:08</td>\n",
       "      <td>business</td>\n",
       "      <td>march volatile stock</td>\n",
       "      <td>new york business march madness college basket...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-03-20 11:36:43</td>\n",
       "      <td>business</td>\n",
       "      <td>stock week ahead big oil rake billion price so...</td>\n",
       "      <td>version story first business bell newsletter s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-03-18 14:26:26</td>\n",
       "      <td>business</td>\n",
       "      <td>oil emergency work home drive say</td>\n",
       "      <td>new york business government around world must...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-03-20 12:57:36</td>\n",
       "      <td>business</td>\n",
       "      <td>opinion technology transforming nature money a...</td>\n",
       "      <td>interview original version originally entirety...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-03-18 17:14:11</td>\n",
       "      <td>business</td>\n",
       "      <td>inflation everywhere except cell phone bill</td>\n",
       "      <td>new york business inflation everywhere grocery...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-03-18 11:32:30</td>\n",
       "      <td>business</td>\n",
       "      <td>king partner refuse close location</td>\n",
       "      <td>new york business king trying suspend operatio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date published  category  \\\n",
       "0 2021-07-15 02:46:59      news   \n",
       "1 2021-05-12 07:52:09      news   \n",
       "2 2021-06-16 02:51:30      news   \n",
       "3 2022-03-18 14:37:21  business   \n",
       "4 2022-03-19 11:41:08  business   \n",
       "5 2022-03-20 11:36:43  business   \n",
       "6 2022-03-18 14:26:26  business   \n",
       "7 2022-03-20 12:57:36  business   \n",
       "8 2022-03-18 17:14:11  business   \n",
       "9 2022-03-18 11:32:30  business   \n",
       "\n",
       "                                            headline  \\\n",
       "0      shortage trucker simple think solution driver   \n",
       "1  servo iron hand could protect factory worker i...   \n",
       "2                               swarm robot get work   \n",
       "3          two year later remote work million career   \n",
       "4                               march volatile stock   \n",
       "5  stock week ahead big oil rake billion price so...   \n",
       "6                  oil emergency work home drive say   \n",
       "7  opinion technology transforming nature money a...   \n",
       "8        inflation everywhere except cell phone bill   \n",
       "9                 king partner refuse close location   \n",
       "\n",
       "                                                text  \n",
       "0  right shortage truck driver commerce boom brou...  \n",
       "1  working factory warehouse mean task repetition...  \n",
       "2  hong warehouse swarm autonomous robot work wor...  \n",
       "3  pandemic thrust working world new reality marc...  \n",
       "4  new york business march madness college basket...  \n",
       "5  version story first business bell newsletter s...  \n",
       "6  new york business government around world must...  \n",
       "7  interview original version originally entirety...  \n",
       "8  new york business inflation everywhere grocery...  \n",
       "9  new york business king trying suspend operatio...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import words\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('words')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# tokenize text\n",
    "def tokenize_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "# remove any non-English words\n",
    "english_words = set(words.words()) \n",
    "def remove_non_english(tokens):\n",
    "    english_tokens = []\n",
    "    for word in tokens:\n",
    "        if word in english_words:\n",
    "            english_tokens.append(word)\n",
    "        else:\n",
    "            english_tokens.append('')\n",
    "    return [token for token in english_tokens if token != '']\n",
    "\n",
    "# apply the functions to both columns\n",
    "def preprocess_column(column):\n",
    "    column = column.apply(tokenize_text)\n",
    "    column = column.apply(remove_non_english)\n",
    "    column = column.apply(lambda tokens: ' '.join(tokens))\n",
    "    return column\n",
    "\n",
    "# apply the preprocessing to both columns\n",
    "df['text'] = preprocess_column(df['text'])\n",
    "df['headline'] = preprocess_column(df['headline'])\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date published    0\n",
      "category          0\n",
      "headline          0\n",
      "text              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check missing values \n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# check duplicated\n",
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date published</th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4506</th>\n",
       "      <td>2017-07-05 17:32:27</td>\n",
       "      <td>news</td>\n",
       "      <td>quiz legit quit</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19168</th>\n",
       "      <td>2015-06-06 17:29:10</td>\n",
       "      <td>sport</td>\n",
       "      <td>champion league live barcelona</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19960</th>\n",
       "      <td>2015-11-20 17:10:22</td>\n",
       "      <td>sport</td>\n",
       "      <td>real barcelona live</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20062</th>\n",
       "      <td>2015-11-06 17:06:21</td>\n",
       "      <td>sport</td>\n",
       "      <td>live premier league football</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21019</th>\n",
       "      <td>2016-05-28 15:58:43</td>\n",
       "      <td>sport</td>\n",
       "      <td>champion league final live</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21093</th>\n",
       "      <td>2016-05-18 10:22:35</td>\n",
       "      <td>news</td>\n",
       "      <td>referendum next</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25303</th>\n",
       "      <td>2018-02-25 00:07:08</td>\n",
       "      <td>sport</td>\n",
       "      <td>winter day result live update</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25311</th>\n",
       "      <td>2018-02-23 00:00:16</td>\n",
       "      <td>sport</td>\n",
       "      <td>day result live update</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25312</th>\n",
       "      <td>2018-02-23 23:59:15</td>\n",
       "      <td>sport</td>\n",
       "      <td>winter day result live update</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25325</th>\n",
       "      <td>2018-02-21 23:59:26</td>\n",
       "      <td>sport</td>\n",
       "      <td>day result live update</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25339</th>\n",
       "      <td>2018-02-20 23:59:58</td>\n",
       "      <td>sport</td>\n",
       "      <td>winter day result live update</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25348</th>\n",
       "      <td>2018-02-19 23:59:27</td>\n",
       "      <td>sport</td>\n",
       "      <td>winter day result live update</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25349</th>\n",
       "      <td>2018-02-19 00:21:03</td>\n",
       "      <td>sport</td>\n",
       "      <td>winter day result live update</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25353</th>\n",
       "      <td>2018-02-18 00:10:05</td>\n",
       "      <td>sport</td>\n",
       "      <td>winter day result live update</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25361</th>\n",
       "      <td>2018-02-16 23:59:44</td>\n",
       "      <td>sport</td>\n",
       "      <td>winter day result live update</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25366</th>\n",
       "      <td>2018-02-16 00:00:15</td>\n",
       "      <td>sport</td>\n",
       "      <td>winter day result live update</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25378</th>\n",
       "      <td>2018-02-14 23:58:16</td>\n",
       "      <td>sport</td>\n",
       "      <td>day result live update</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25387</th>\n",
       "      <td>2018-02-13 00:01:36</td>\n",
       "      <td>sport</td>\n",
       "      <td>day live update</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25394</th>\n",
       "      <td>2018-02-13 23:59:21</td>\n",
       "      <td>sport</td>\n",
       "      <td>day live update</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25397</th>\n",
       "      <td>2018-02-12 00:55:42</td>\n",
       "      <td>sport</td>\n",
       "      <td>winter day live update</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25416</th>\n",
       "      <td>2018-02-11 01:04:50</td>\n",
       "      <td>sport</td>\n",
       "      <td>winter day live update</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25419</th>\n",
       "      <td>2018-02-10 00:00:42</td>\n",
       "      <td>sport</td>\n",
       "      <td>day result live update</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25609</th>\n",
       "      <td>2018-03-16 10:54:47</td>\n",
       "      <td>sport</td>\n",
       "      <td>champion league draw live tie decided</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26296</th>\n",
       "      <td>2018-06-14 13:30:08</td>\n",
       "      <td>sport</td>\n",
       "      <td>live world cup day opening ceremony russia</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date published category  \\\n",
       "4506  2017-07-05 17:32:27     news   \n",
       "19168 2015-06-06 17:29:10    sport   \n",
       "19960 2015-11-20 17:10:22    sport   \n",
       "20062 2015-11-06 17:06:21    sport   \n",
       "21019 2016-05-28 15:58:43    sport   \n",
       "21093 2016-05-18 10:22:35     news   \n",
       "25303 2018-02-25 00:07:08    sport   \n",
       "25311 2018-02-23 00:00:16    sport   \n",
       "25312 2018-02-23 23:59:15    sport   \n",
       "25325 2018-02-21 23:59:26    sport   \n",
       "25339 2018-02-20 23:59:58    sport   \n",
       "25348 2018-02-19 23:59:27    sport   \n",
       "25349 2018-02-19 00:21:03    sport   \n",
       "25353 2018-02-18 00:10:05    sport   \n",
       "25361 2018-02-16 23:59:44    sport   \n",
       "25366 2018-02-16 00:00:15    sport   \n",
       "25378 2018-02-14 23:58:16    sport   \n",
       "25387 2018-02-13 00:01:36    sport   \n",
       "25394 2018-02-13 23:59:21    sport   \n",
       "25397 2018-02-12 00:55:42    sport   \n",
       "25416 2018-02-11 01:04:50    sport   \n",
       "25419 2018-02-10 00:00:42    sport   \n",
       "25609 2018-03-16 10:54:47    sport   \n",
       "26296 2018-06-14 13:30:08    sport   \n",
       "\n",
       "                                         headline text  \n",
       "4506                              quiz legit quit       \n",
       "19168              champion league live barcelona       \n",
       "19960                         real barcelona live       \n",
       "20062                live premier league football       \n",
       "21019                  champion league final live       \n",
       "21093                             referendum next       \n",
       "25303               winter day result live update       \n",
       "25311                      day result live update       \n",
       "25312               winter day result live update       \n",
       "25325                      day result live update       \n",
       "25339               winter day result live update       \n",
       "25348               winter day result live update       \n",
       "25349               winter day result live update       \n",
       "25353               winter day result live update       \n",
       "25361               winter day result live update       \n",
       "25366               winter day result live update       \n",
       "25378                      day result live update       \n",
       "25387                             day live update       \n",
       "25394                             day live update       \n",
       "25397                      winter day live update       \n",
       "25416                      winter day live update       \n",
       "25419                      day result live update       \n",
       "25609       champion league draw live tie decided       \n",
       "26296  live world cup day opening ceremony russia       "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check empty string in text column\n",
    "df[df['text'] == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date published</th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>2020-01-23 17:36:04</td>\n",
       "      <td>business</td>\n",
       "      <td></td>\n",
       "      <td>outskirt one best medieval city one world mode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2368</th>\n",
       "      <td>2021-01-22 11:25:25</td>\n",
       "      <td>news</td>\n",
       "      <td></td>\n",
       "      <td>series essay distance lake telling story pande...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>2015-02-27 18:56:55</td>\n",
       "      <td>news</td>\n",
       "      <td></td>\n",
       "      <td>story highlight gene gene may star trek charac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4359</th>\n",
       "      <td>2014-02-19 14:44:18</td>\n",
       "      <td>health</td>\n",
       "      <td></td>\n",
       "      <td>story highlight conflicting message regarding ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4508</th>\n",
       "      <td>2017-05-16 17:43:26</td>\n",
       "      <td>entertainment</td>\n",
       "      <td></td>\n",
       "      <td>story highlight show ran nine season original ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31906</th>\n",
       "      <td>2020-01-31 18:49:17</td>\n",
       "      <td>sport</td>\n",
       "      <td></td>\n",
       "      <td>start thrilling new rivalry sign good rookie p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32895</th>\n",
       "      <td>2020-07-23 08:08:27</td>\n",
       "      <td>sport</td>\n",
       "      <td></td>\n",
       "      <td>supposed week celebration japan would opening ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35298</th>\n",
       "      <td>2021-05-07 12:29:03</td>\n",
       "      <td>news</td>\n",
       "      <td></td>\n",
       "      <td>version story may edition royal news weekly di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36053</th>\n",
       "      <td>2021-07-02 15:07:53</td>\n",
       "      <td>news</td>\n",
       "      <td></td>\n",
       "      <td>look life president personal birth date august...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38897</th>\n",
       "      <td>2023-03-07 00:00:00</td>\n",
       "      <td>weather</td>\n",
       "      <td></td>\n",
       "      <td>climate pattern pacific ocean along equator im...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date published       category headline  \\\n",
       "863   2020-01-23 17:36:04       business            \n",
       "2368  2021-01-22 11:25:25           news            \n",
       "2499  2015-02-27 18:56:55           news            \n",
       "4359  2014-02-19 14:44:18         health            \n",
       "4508  2017-05-16 17:43:26  entertainment            \n",
       "...                   ...            ...      ...   \n",
       "31906 2020-01-31 18:49:17          sport            \n",
       "32895 2020-07-23 08:08:27          sport            \n",
       "35298 2021-05-07 12:29:03           news            \n",
       "36053 2021-07-02 15:07:53           news            \n",
       "38897 2023-03-07 00:00:00        weather            \n",
       "\n",
       "                                                    text  \n",
       "863    outskirt one best medieval city one world mode...  \n",
       "2368   series essay distance lake telling story pande...  \n",
       "2499   story highlight gene gene may star trek charac...  \n",
       "4359   story highlight conflicting message regarding ...  \n",
       "4508   story highlight show ran nine season original ...  \n",
       "...                                                  ...  \n",
       "31906  start thrilling new rivalry sign good rookie p...  \n",
       "32895  supposed week celebration japan would opening ...  \n",
       "35298  version story may edition royal news weekly di...  \n",
       "36053  look life president personal birth date august...  \n",
       "38897  climate pattern pacific ocean along equator im...  \n",
       "\n",
       "[72 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check empty string in headline column\n",
    "df[df['headline'] == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out empty string for both columns\n",
    "df = df[df['text'] != '']\n",
    "df = df[df['headline'] != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date published    0\n",
      "category          0\n",
      "headline          0\n",
      "text              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date published</th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [date published, category, headline, text]\n",
       "Index: []"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['text'] == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date published</th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [date published, category, headline, text]\n",
       "Index: []"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['headline'] == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41688, 4)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"cnn_news_articles_final_cleaned.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
